{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import packages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","import numpy as np\n","import time\n","import os\n","import torch.backends.cudnn as cudnn\n","\n","import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n","from datetime import datetime\n","from pytz import timezone\n","\n","import ssl\n","\n","from torchsummary import summary #!#\n","from tensorboardX import SummaryWriter #!#\n","ssl.create_default_https_context = ssl._create_unverified_context"]},{"cell_type":"markdown","metadata":{},"source":["Functions for Randaugment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#from .Mosaic import mosaic\n","\n","def AutoContrast(img, _):\n","    return PIL.ImageOps.autocontrast(img)\n","\n","def Brightness(img, v):\n","    assert v >= 0.0\n","    return PIL.ImageEnhance.Brightness(img).enhance(v)\n","\n","def Color(img, v):\n","    assert v >= 0.0\n","    return PIL.ImageEnhance.Color(img).enhance(v)\n","\n","def Contrast(img, v):\n","    assert v >= 0.0\n","    return PIL.ImageEnhance.Contrast(img).enhance(v)\n","\n","def Equalize(img, _):\n","    return PIL.ImageOps.equalize(img)\n","\n","def Invert(img, _):\n","    return PIL.ImageOps.invert(img)\n","\n","def Identity(img, v):\n","    return img\n","\n","def Posterize(img, v):  # [4, 8]\n","    v = int(v)\n","    v = max(1, v)\n","    return PIL.ImageOps.posterize(img, v)\n","\n","def Rotate(img, v):  # [-30, 30]\n","    #assert -30 <= v <= 30\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    return img.rotate(v)\n","\n","def Sharpness(img, v):  # [0.1,1.9]\n","    assert v >= 0.0\n","    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n","\n","def ShearX(img, v):  # [-0.3, 0.3]\n","    #assert -0.3 <= v <= 0.3\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n","\n","def ShearY(img, v):  # [-0.3, 0.3]\n","    #assert -0.3 <= v <= 0.3\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n","\n","def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    #assert -0.3 <= v <= 0.3\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    v = v * img.size[0]\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    #assert v >= 0.0\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    #assert -0.3 <= v <= 0.3\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    v = v * img.size[1]\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n","\n","def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    #assert 0 <= v\n","    #if random.random() > 0.5:\n","    #    v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n","\n","def Solarize(img, v):  # [0, 256]\n","    assert 0 <= v <= 256\n","    return PIL.ImageOps.solarize(img, v)\n","\n","def Cutout(img, v):  #[0, 60] => percentage: [0, 0.2] => change to [0, 0.5]\n","    assert 0.0 <= v <= 0.5\n","    if v <= 0.:\n","        return img\n","\n","    v = v * img.size[0]\n","    return CutoutAbs(img, v)\n","\n","def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n","    # assert 0 <= v <= 20\n","    if v < 0:\n","        return img\n","    w, h = img.size\n","    x0 = np.random.uniform(w)\n","    y0 = np.random.uniform(h)\n","\n","    x0 = int(max(0, x0 - v / 2.))\n","    y0 = int(max(0, y0 - v / 2.))\n","    x1 = min(w, x0 + v)\n","    y1 = min(h, y0 + v)\n","\n","    xy = (x0, y0, x1, y1)\n","    color = (125, 123, 114)\n","    # color = (0, 0, 0)\n","    img = img.copy()\n","    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n","    return img\n","\n","def augment_list():  \n","    l = [\n","        (AutoContrast, 0, 1),\n","        (Brightness, 0.05, 0.95),\n","        (Color, 0.05, 0.95),\n","        (Contrast, 0.05, 0.95),\n","        (Equalize, 0, 1),\n","        (Identity, 0, 1),\n","        (Posterize, 4, 8),\n","        (Rotate, -30, 30),\n","        (Sharpness, 0.05, 0.95),\n","        (ShearX, -0.3, 0.3),\n","        (ShearY, -0.3, 0.3),\n","        (Solarize, 0, 256),\n","        (TranslateX, -0.3, 0.3),\n","        (TranslateY, -0.3, 0.3)\n","    ]\n","    return l\n","\n","\n","class RandAugment:\n","    def __init__(self, n, m):\n","        self.n = n\n","        self.m = m      # [0, 30] in fixmatch, deprecated.\n","        self.augment_list = augment_list()\n","\n","        \n","    def __call__(self, img):\n","        ops = random.choices(self.augment_list, k=self.n)\n","        for op, min_val, max_val in ops:\n","            val = min_val + float(max_val - min_val)*random.random()\n","            img = op(img, val) \n","        cutout_val = random.random() * 0.5         \n","        img = Cutout(img, cutout_val) #for fixmatch\n","        return img"]},{"cell_type":"markdown","metadata":{},"source":["To build ResNet-50 model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = out + self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","# BottleNeck for ResNet 50\n","class BottleNeck(nn.Module): #!#\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n","            )\n","            \n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x  #!#\n","\n","# DropBlock\n","class DropBlock2D(nn.Module):\n","    r\"\"\"Randomly zeroes 2D spatial blocks of the input tensor.\n","    As described in the paper\n","    `DropBlock: A regularization method for convolutional networks`_ ,\n","    dropping whole blocks of feature map allows to remove semantic\n","    information as compared to regular dropout.\n","    Args:\n","        drop_prob (float): probability of an element to be dropped.\n","        block_size (int): size of the block to drop\n","    Shape:\n","        - Input: `(N, C, H, W)`\n","        - Output: `(N, C, H, W)`\n","    .. _DropBlock: A regularization method for convolutional networks:\n","       https://arxiv.org/abs/1810.12890\n","    \"\"\"\n","\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock2D, self).__init__()\n","\n","        self.drop_prob = drop_prob\n","        self.block_size = block_size\n","\n","    def forward(self, x):\n","        # shape: (bsize, channels, height, width)\n","\n","        assert x.dim() == 4, \\\n","            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n","\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self._compute_gamma(x)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n","            # place mask on input device\n","            mask = mask.to(x.device)\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","\n","            return out\n","\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n","                                  kernel_size=(self.block_size, self.block_size),\n","                                  stride=(1, 1),\n","                                  padding=self.block_size // 2)\n","\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1]\n","\n","        block_mask = 1 - block_mask.squeeze(1)\n","\n","        return block_mask\n","\n","    def _compute_gamma(self, x):\n","        return self.drop_prob / (self.block_size ** 2)\n","    \n","    \n","# Linear Scheduler\n","class LinearScheduler(nn.Module):\n","    def __init__(self, dropblock, start_value, stop_value, nr_steps):\n","        super(LinearScheduler, self).__init__()\n","        self.dropblock = dropblock\n","        self.i = 0\n","        self.drop_values = np.linspace(start=start_value, stop=stop_value, num=int(nr_steps))\n","\n","    def forward(self, x):\n","        return self.dropblock(x)\n","\n","    def step(self):\n","        if self.i < len(self.drop_values):\n","            self.dropblock.drop_prob = self.drop_values[self.i]\n","\n","        self.i += 1\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.dropblock = LinearScheduler(DropBlock2D(drop_prob=0.3, block_size=4), start_value=0, stop_value=0.5, nr_steps=1e3) #!#\n","        \n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.dropblock(out)\n","        \n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.dropblock(out) #!#\n","        \n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.dropblock(out) #!#\n","        \n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def train(epoch):\n","    \n","    model.train()\n","    train_loss = 0 \n","    total = 0\n","    correct = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            data, target = Variable(data.cuda()), Variable(target.cuda())\n","        else:\n","            data, target = Variable(data), Variable(target)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, predicted = torch.max(output.data, 1)\n","\n","        total += target.size(0)\n","        correct += predicted.eq(target.data).cpu().sum()\n","        if batch_idx % 10 == 0:\n","            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n","                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n","            print(\"lr:\", optimizer.param_groups[0]['lr']) #!#\n","            \n","            writer.add_scalar('training loss', (train_loss/(batch_idx + 1)), epoch * len(train_loader) + batch_idx) #!#\n","            writer.add_scalar('training accuracy', (100. * correct / total), epoch * len(train_loader) + batch_idx) #!#\n","            writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch * len(train_loader) + batch_idx) #!#\n","\n","\n","def test(epoch): #!#\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            data, target = Variable(data.cuda()), Variable(target.cuda())\n","        else:\n","            data, target = Variable(data), Variable(target)\n","\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","\n","        test_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += target.size(0)\n","        correct += predicted.eq(target.data).cpu().sum()\n","        \n","        writer.add_scalar('test loss', test_loss / (batch_idx + 1), epoch * len(test_loader) + batch_idx) #!#\n","        writer.add_scalar('test accuracy', 100. * correct / total, epoch * len(test_loader) + batch_idx) #!#\n","        \n","    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n","          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n","\n","\n","def save_checkpoint(directory, state, filename='latest.tar.gz'):\n","\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","    model_filename = os.path.join(directory, filename)\n","    torch.save(state, model_filename)\n","    print(\"=> saving checkpoint\")\n","\n","def load_checkpoint(directory, filename='latest.tar.gz'):\n","\n","    model_filename = os.path.join(directory, filename)\n","    if os.path.exists(model_filename):\n","        print(\"=> loading checkpoint\")\n","        state = torch.load(model_filename)\n","        return state\n","    else:\n","        return None"]},{"cell_type":"markdown","metadata":{},"source":["Main function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f59363181caa45cb99919a407f550735","96aef0ed53634596bef74926e4fbbb29","65d24562ce364f139637cfd8d78706f6","80f48ad72cd04b41b38044adb0aaba66","bc0e29598f684a678861649b5406cecf","9cf4e96efb784c61ad5c08d649c617d0","45c21f45019c456a88b635d81460ccf9","047016a525984f9a8f513efbda071056","c8a94236df1846aba8ca772bb8b8f2fc","17b3620f151d45a4925d79eb28451abf","3ce7b447289a4a439da6761da82854e5"]},"id":"lJPMmk7Y_2Zn","outputId":"4b756e10-3924-48e3-a1c2-3fcaea58c475"},"outputs":[],"source":["if __name__ =='__main__':\n","    \n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n","    start_time = time.time()\n","    batch_size = 128\n","    learning_rate = 0.01\n","\n","    now_str = datetime.now(timezone('Asia/Seoul')).strftime('%Y-%m-%d_%H_%M_%S')\n","\n","    root_dir = './app/cifar10/'\n","    default_directory = './app/torch/save_models/ResNet50/dropblock4_Adam_22'\n","\n","    writer = SummaryWriter('./runs/' + now_str + '/graph')  #!#\n","\n","    # Data Augmentation\n","    transform_train = transforms.Compose([\n","        # transforms.Resize((32,32)), #!#\n","        transforms.RandomCrop(32, padding=4),               # Random Position Crop\n","        RandAugment(3, 8),                               # Random Augmentation #!#\n","        transforms.RandomHorizontalFlip(),                  # right and left flip\n","        transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n","        transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n","                             std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n","        transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n","                             std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n","    ])\n","\n","# automatically download\n","    train_dataset = datasets.CIFAR10(root=root_dir,\n","                                     train=True,\n","                                     transform=transform_train,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root=root_dir,\n","                                    train=False,\n","                                    transform=transform_test)\n","\n","    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                               batch_size=batch_size,\n","                                               shuffle=True,            # at Training Procedure, Data Shuffle = True\n","                                               num_workers=4)           # CPU loader number\n","\n","    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                              batch_size=batch_size,\n","                                              shuffle=False,            # at Test Procedure, Data Shuffle = False\n","                                              num_workers=4)            # CPU loader number\n","    \n","    \n","    model = ResNet(BottleNeck, [3, 4, 6, 3])\n","\n","    modelses = model #!#\n","        \n","    modelses.cuda() #!#\n","    summary(modelses,(3,32,32)) #!# \n","    \n","    if torch.cuda.device_count() > 0:\n","        print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n","        model = nn.DataParallel(model).cuda()\n","        cudnn.benchmark = True\n","    else:\n","        print(\"USE ONLY CPU!\")\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate) #!#\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    start_epoch = 0\n","\n","    checkpoint = load_checkpoint(default_directory)\n","    if not checkpoint:\n","        pass\n","    else:\n","        start_epoch = checkpoint['epoch'] + 1\n","        model.load_state_dict(checkpoint['state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","        \n","    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.988) #!#\n","\n","    for epoch in range(start_epoch, 160):\n","            \n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = optimizer.param_groups[0]['lr'] #!#\n","    \n","        train(epoch)\n","        save_checkpoint(default_directory, {\n","            'epoch': epoch,\n","            'model': model,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","        })\n","        test(epoch)  \n","        \n","        scheduler.step() #!#\n","\n","    now = time.gmtime(time.time() - start_time)\n","    print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"]},{"cell_type":"markdown","metadata":{},"source":["Code for Ensemble learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uv4_9fgwiIFm"},"outputs":[],"source":["default_directory1 =  './app/torch/save_models/ResNet50/dropblock4_Adam_15_93'\n","default_directory2 =  './app/torch/save_models/ResNet50/dropblock4_Adam_17_92'\n","default_directory3 =  './app/torch/save_models/ResNet50/dropblock4_Adam_18_93'\n","default_directory4 =  './app/torch/save_models/ResNet50/dropblock4_Adam_19'\n","default_directory5 =  './app/torch/save_models/ResNet50/dropblock4_Adam_20_93'\n","\n","root_dir = './app/cifar10/'\n","batch_size = 32\n","\n","writer = SummaryWriter('runs/graph/do_ensemble/dropblock4_Adam') #!#\n","start_time = time.time()\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n","    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n","                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n","])\n","\n","test_dataset = datasets.CIFAR10(root=root_dir,\n","                                train=False,\n","                                transform=transform_test)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n","                                          num_workers=0)            # CPU loader number\n","\n","# BottleNeck for ResNet 50\n","class BottleNeck(nn.Module): #!#\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n","            )\n","            \n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x  #!#\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","model1 = ResNet(BottleNeck, [3, 4, 6, 3])\n","model2 = ResNet(BottleNeck, [3, 4, 6, 3])\n","model3 = ResNet(BottleNeck, [3, 4, 6, 3])\n","model4 = ResNet(BottleNeck, [3, 4, 6, 3])\n","model5 = ResNet(BottleNeck, [3, 4, 6, 3])\n","\n","criterion1 = nn.CrossEntropyLoss()\n","criterion2 = nn.CrossEntropyLoss()\n","criterion3 = nn.CrossEntropyLoss()\n","criterion4 = nn.CrossEntropyLoss()\n","criterion5 = nn.CrossEntropyLoss()\n","\n","if torch.cuda.device_count() > 0:\n","    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n","    model1 = nn.DataParallel(model1).cuda()\n","    model2 = nn.DataParallel(model2).cuda()\n","    model3 = nn.DataParallel(model3).cuda()\n","    model4 = nn.DataParallel(model4).cuda()\n","    model5 = nn.DataParallel(model5).cuda()\n","    cudnn.benchmark = True\n","else:\n","    print(\"USE ONLY CPU!\")\n","\n","\n","def test(epoch):\n","    model1.eval()\n","    model2.eval()\n","    model3.eval()\n","    model4.eval()\n","    model5.eval()\n","    \n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            data, target = Variable(data.cuda()), Variable(target.cuda())\n","        else:\n","            data, target = Variable(data), Variable(target)\n","\n","        outputs1 = model1(data)\n","        loss1 = criterion1(outputs1, target)\n","        \n","        outputs2 = model2(data)\n","        loss2 = criterion2(outputs2, target)\n","        \n","        outputs3 = model3(data)\n","        loss3 = criterion3(outputs3, target)\n","        \n","        outputs4 = model4(data)\n","        loss4 = criterion4(outputs4, target)\n","        \n","        outputs5 = model5(data)\n","        loss5 = criterion5(outputs5, target)\n","        \n","        loss = ( loss1 + loss2 + loss3 + loss4 + loss5 )/ 5\n","        outputs = (outputs1 + outputs2 + outputs3 + outputs4 + outputs5)/5\n","        \n","        \n","        test_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += target.size(0)\n","        correct += predicted.eq(target.data).cpu().sum()\n","        \n","        writer.add_scalar('test loss', test_loss / (batch_idx + 1), epoch * len(test_loader)+ batch_idx) #!#\n","        writer.add_scalar('test accuracy', 100. * correct / total, epoch * len(test_loader)+ batch_idx) #!#\n","        \n","    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n","          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n","\n","\n","def load_checkpoint(directory, filename='latest.tar.gz'):\n","\n","    model_filename = os.path.join(directory, filename)\n","    if os.path.exists(model_filename):\n","        print(\"=> loading checkpoint\")\n","        state = torch.load(model_filename)\n","        return state\n","    else:\n","        return None\n","\n","start_epoch = 0\n","\n","checkpoint1 = load_checkpoint(default_directory1)\n","checkpoint2 = load_checkpoint(default_directory2)\n","checkpoint3 = load_checkpoint(default_directory3)\n","checkpoint4 = load_checkpoint(default_directory4)\n","checkpoint5 = load_checkpoint(default_directory5)\n","\n","model1.load_state_dict(checkpoint1['state_dict'])\n","model2.load_state_dict(checkpoint2['state_dict'])\n","model3.load_state_dict(checkpoint3['state_dict'])\n","model4.load_state_dict(checkpoint4['state_dict'])\n","model5.load_state_dict(checkpoint5['state_dict'])\n","\n","for epoch in range(start_epoch, 1):\n","    test(epoch)  \n","\n","now = time.gmtime(time.time() - start_time)\n","print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"2021222992_박준현","provenance":[{"file_id":"https://github.com/heechul-knu/colab/blob/master/Resnet.ipynb","timestamp":1637213702909}]},"interpreter":{"hash":"94f88352a9f8498e8f61c34d695978bb607a56f30cc8f240166bc12e0012e76f"},"kernelspec":{"display_name":"Python 3.8.0 64-bit ('Research': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"047016a525984f9a8f513efbda071056":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17b3620f151d45a4925d79eb28451abf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ce7b447289a4a439da6761da82854e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45c21f45019c456a88b635d81460ccf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65d24562ce364f139637cfd8d78706f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c21f45019c456a88b635d81460ccf9","placeholder":"​","style":"IPY_MODEL_9cf4e96efb784c61ad5c08d649c617d0","value":""}},"80f48ad72cd04b41b38044adb0aaba66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8a94236df1846aba8ca772bb8b8f2fc","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_047016a525984f9a8f513efbda071056","value":170498071}},"96aef0ed53634596bef74926e4fbbb29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf4e96efb784c61ad5c08d649c617d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc0e29598f684a678861649b5406cecf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ce7b447289a4a439da6761da82854e5","placeholder":"​","style":"IPY_MODEL_17b3620f151d45a4925d79eb28451abf","value":" 170499072/? [00:06&lt;00:00, 31072180.45it/s]"}},"c8a94236df1846aba8ca772bb8b8f2fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f59363181caa45cb99919a407f550735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65d24562ce364f139637cfd8d78706f6","IPY_MODEL_80f48ad72cd04b41b38044adb0aaba66","IPY_MODEL_bc0e29598f684a678861649b5406cecf"],"layout":"IPY_MODEL_96aef0ed53634596bef74926e4fbbb29"}}}}},"nbformat":4,"nbformat_minor":0}
